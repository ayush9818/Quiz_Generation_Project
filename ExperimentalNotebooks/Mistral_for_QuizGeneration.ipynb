{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "67fcf79d-1241-49f1-a99e-fca038408603",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip install transformers torch\n",
    "#! pip install langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "d5b78ed1-a41a-4728-907e-0eb4db9b8bc5",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'HuggingFaceLLM' from 'langchain.llms' (/home/aagarwal/miniconda3/envs/OpenShape/lib/python3.9/site-packages/langchain/llms/__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[62], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mllms\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m HuggingFaceLLM\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'HuggingFaceLLM' from 'langchain.llms' (/home/aagarwal/miniconda3/envs/OpenShape/lib/python3.9/site-packages/langchain/llms/__init__.py)"
     ]
    }
   ],
   "source": [
    "from langchain.llms import HuggingFaceLLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "126607dd-34e8-4659-8fc1-6820a8a33f96",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'HuggingFaceLLM' from 'langchain.llms' (/home/aagarwal/miniconda3/envs/OpenShape/lib/python3.9/site-packages/langchain/llms/__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[56], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mllms\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m HuggingFaceLLM\n\u001b[1;32m      3\u001b[0m model_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmistralai/Mistral-7B-Instruct-v0.2\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Initialize the Mistral model from Hugging Face\u001b[39;00m\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'HuggingFaceLLM' from 'langchain.llms' (/home/aagarwal/miniconda3/envs/OpenShape/lib/python3.9/site-packages/langchain/llms/__init__.py)"
     ]
    }
   ],
   "source": [
    "from langchain.llms import HuggingFaceLLM\n",
    "\n",
    "model_name = 'mistralai/Mistral-7B-Instruct-v0.2'\n",
    "# Initialize the Mistral model from Hugging Face\n",
    "mistral_model = HuggingFaceLLM(model_name=model_name)\n",
    "\n",
    "# Now you can use the `mistral_model` instance to generate text, answer questions, etc.\n",
    "# For example, to generate text:\n",
    "prompt = \"Once upon a time\"\n",
    "generated_text = mistral_model(prompt)\n",
    "\n",
    "print(generated_text)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9c3cb9fd-c60c-4858-b03f-dd25c32a0885",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM, GenerationConfig\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4747e2fd-1637-4bd3-bf3a-95be334e7c3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"max_split_size_mb:128\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9fb0cf5b-2b59-456c-8bc2-328576702b1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 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"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3fa426af-e570-4ce5-b90a-79cdd2644412",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e2916fb4b4ad4713a438f18c7fe61c00",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "\n",
    "#model_name = 'google/gemma-7b'\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name, torch_dtype=torch.float16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d6fcff13-f096-4d07-9962-5dd59bf3dec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "device='cuda:3'\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "48b27226-9fa1-4496-b404-1a5ed903a84d",
   "metadata": {},
   "outputs": [],
   "source": [
    "generation_config = GenerationConfig(\n",
    "    max_new_tokens=2000, \n",
    "    do_sample=True, \n",
    "    top_k=50, \n",
    "    top_p=0.9,\n",
    "    num_beams=2,\n",
    "    early_stopping=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a15a956f-1c1b-4108-9465-619ffa211a7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def generate_quiz(topic, num_questions, generation_config):\n",
    "#     prompt = f\"Based on the topic '{topic}', generate {num_questions} multiple-choice questions with 4 options each along with answers. Ensure clarity and relevance to the topic.\"\n",
    "\n",
    "#     input_ids = tokenizer(prompt, return_tensors='pt').to(device)\n",
    "\n",
    "#     output = model.generate(**input_ids, generation_config=generation_config)\n",
    "\n",
    "#     return tokenizer.decode(output[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "fc88f6c4-ef2a-40ea-a6b5-e712c8658d82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate_quiz('Generative Adversial Networks', 5, generation_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "ed7460d5-7d60-4b7c-ad2d-6e633d7ebeea",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<s> \n",
      "Generate a MCQ Quiz with 5 Questions Choices each on Recommendation Systems. \n",
      "The difficulty of Questions should be advanced level. Make sure to give meaningful options. \n",
      "The Questions should include advanced statistical as well as mathematical questions as well.\n",
      "Include Answers to the questions as well as the explanations.\n",
      "\n",
      "The Quiz should be in the below json format \n",
      "sample respone = {\n",
      "    \"question\" : \"Ques should be here\",\n",
      "    \"option1\" : \"Choice 1 should be here\",\n",
      "    \"option2\" : \"Choice 2 should be here\",\n",
      "    \"option3\" : \"Choice 3 should be here\",\n",
      "    \"option4\" : \"Choice 4 should be here\",\n",
      "    \"Answer\" : \"Option no which is is the correct answer\",\n",
      "    \"Explantion\" : \"Explanation to anser should be here\"\n",
      "}\n",
      "\n",
      "The output should be only in JSON format. No extra text. Input text should also not appear in answer.\n",
      "\n",
      "[\n",
      "  {\n",
      "    \"question\" : \"Given a user-item matrix, how can we calculate the implicit rating for a user and an item pair where no explicit rating is present?\",\n",
      "    \"option1\" : \"Using Collaborative Filtering, we can calculate the implicit rating based on the ratings of similar users.\",\n",
      "    \"option2\" : \"Using Content Based Filtering, we can calculate the implicit rating based on the similarity of the content of the user's past ratings and the item.\",\n",
      "    \"option3\" : \"Using Matrix Factorization techniques like Singular Value Decomposition (SVD) or Non-Negative Matrix Factorization (NMF), we can calculate the implicit rating by predicting the latent features of the user and item.\",\n",
      "    \"option4\" : \"We cannot calculate the implicit rating without any explicit rating data.\",\n",
      "    \"Answer\" : \"option3\",\n",
      "    \"Explanation\" : \"Implicit ratings can be calculated using Matrix Factorization techniques like SVD or NMF which help predict the latent features of the user and item.\"\n",
      "  },\n",
      "  {\n",
      "    \"question\" : \"Which of the following is a measure of the similarity between two items, given a user-item matrix?\",\n",
      "    \"option1\" : \"Cosine similarity\",\n",
      "    \"option2\" : \"Jaccard Similarity\",\n",
      "    \"option3\" : \"Pearson Correlation Coefficient\",\n",
      "    \"option4\" : \"Spearman Rank Correlation Coefficient\",\n",
      "    \"Answer\" : \"option1\",\n",
      "    \"Explanation\" : \"Cosine similarity is a measure of the similarity between two vectors, and is commonly used for measuring item similarity in a user-item matrix.\"\n",
      "  },\n",
      "  {\n",
      "    \"question\" : \"Consider the following equation for Collaborative Filtering, where R is the user-item rating matrix, U and V are the user and item latent feature matrices respectively, and λ is the regularization parameter:\n",
      "\n",
      "    (R^T R + λ I) U = R^T Y\n",
      "\n",
      "    Given this equation, how would you interpret the term (R^T R)?\",\n",
      "    \"option1\" : \"The term (R^T R) represents the dot product of the transpose of the user-item rating matrix R, and the user-item rating matrix R itself.\",\n",
      "    \"option2\" : \"The term (R^T R) represents the dot product of the user-item rating matrix R, and the transpose of the user-item rating matrix R.\",\n",
      "    \"option3\" : \"The term (R^T R) represents the identity matrix I.\",\n",
      "    \"option4\" : \"The term (R^T R) represents the regularization parameter λ.\",\n",
      "    \"Answer\" : \"option1\",\n",
      "    \"Explanation\" : \"The term (R^T R) in the equation represents the dot product of the transpose of the user-item rating matrix R, and the user-item rating matrix R itself, forming a matrix of user-user similarities.\"\n",
      "  },\n",
      "  {\n",
      "    \"question\" : \"Given a user-item matrix R, where each entry represents an explicit rating, and the ratings are on a scale of 1 to 5, which of the following techniques would you use to obtain implicit ratings for new items?\",\n",
      "    \"option1\" : \"Matrix Factorization techniques like SVD or NMF can be used to predict implicit ratings based on the user's past explicit ratings and the item features.\",\n",
      "    \"option2\" : \"Collaborative Filtering techniques can be used to predict implicit ratings based on the ratings of similar users.\",\n",
      "    \"option3\" : \"Content Based Filtering techniques can be used to predict implicit ratings based on the content of the items.\",\n",
      "    \"option4\" : \"Implicit ratings cannot be obtained from a user-item matrix, only explicit ratings are present.\",\n",
      "    \"Answer\" : \"option1\",\n",
      "    \"Explanation\" : \"Matrix Factorization techniques like SVD or NMF can be used to predict implicit ratings based on the user's past explicit ratings and the item features.\"\n",
      "  },\n",
      "  {\n",
      "    \"question\" : \"Given a user-item matrix R, where each entry represents a rating, and the ratings are on a scale of 1 to 5. Suppose we have two items i and j, and their ratings by a user u are r\\_iu = 5 and r\\_ju = 3 respectively. Which of the following statements is true about the cosine similarity between items i and j?\",\n",
      "    \"option1\" : \"The cosine similarity between items i and j is greater than 1.\",\n",
      "    \"option2\" : \"The cosine similarity between items i and j is equal to 0.\",\n",
      "    \"option3\" : \"The cosine similarity between items i and j is less than 0.\",\n",
      "    \"option4\" : \"The cosine similarity between items i and j cannot be determined from the given information.\",\n",
      "    \"Answer\" : \"option4\",\n",
      "    \"Explanation\" : \"The cosine similarity between items i and j cannot be determined from the given information alone, as it also depends on the vectors representing the items in the user-item matrix.\"\n",
      "  }\n",
      "]</s>\n"
     ]
    }
   ],
   "source": [
    "prompt = \"\"\"\n",
    "Generate a MCQ Quiz with 5 Questions Choices each on Recommendation Systems. \n",
    "The difficulty of Questions should be advanced level. Make sure to give meaningful options. \n",
    "The Questions should include advanced statistical as well as mathematical questions as well.\n",
    "Include Answers to the questions as well as the explanations.\n",
    "\n",
    "The Quiz should be in the below json format \n",
    "sample respone = {\n",
    "    \"question\" : \"Ques should be here\",\n",
    "    \"option1\" : \"Choice 1 should be here\",\n",
    "    \"option2\" : \"Choice 2 should be here\",\n",
    "    \"option3\" : \"Choice 3 should be here\",\n",
    "    \"option4\" : \"Choice 4 should be here\",\n",
    "    \"Answer\" : \"Option no which is is the correct answer\",\n",
    "    \"Explantion\" : \"Explanation to anser should be here\"\n",
    "}\n",
    "\n",
    "The output should be only in JSON format. No extra text.\n",
    "\"\"\"\n",
    "input_ids = tokenizer(prompt, return_tensors='pt').to(device)\n",
    "\n",
    "outputs = model.generate(**input_ids, \n",
    "                         max_new_tokens=10000, \n",
    "                         top_p=0.9, \n",
    "                         top_k=5,\n",
    "                         early_stopping=True,\n",
    "                         do_sample=True)\n",
    "\n",
    "print(tokenizer.decode(outputs[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "c19b4f67-5d88-4c72-834b-573556d1d172",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = \"\"\"\n",
    "[\n",
    "  {\n",
    "    \"question\" : \"Consider a user who has rated 15 movies, out of which 10 have a rating of 5 stars and the rest have a rating of 3 stars. A new movie is to be recommended to the user, which of the following methods would be most effective for this scenario?\",\n",
    "    \"option1\" : \"Content Based Filtering using cosine similarity\",\n",
    "    \"option2\" : \"Matrix Factorization using Singular Value Decomposition (SVD)\",\n",
    "    \"option3\" : \"Collaborative Filtering using User-User Similarity\",\n",
    "    \"option4\" : \"Collaborative Filtering using Item-Item Similarity\",\n",
    "    \"Answer\" : \"option3\",\n",
    "    \"Explanation\" : \"In this scenario, the user's preferences are skewed towards a specific rating, hence User-User Similarity based Collaborative Filtering would be the most effective approach to recommend a movie that the user is likely to rate highly.\"\n",
    "  },\n",
    "  {\n",
    "    \"question\" : \"Given a dataset with 100 users, 50 items, and 500 ratings, which recommendation algorithm would you recommend for this scenario, considering the computational complexity?\",\n",
    "    \"option1\" : \"Matrix Factorization using Alternating Least Squares (ALS)\",\n",
    "    \"option2\" : \"Content Based Filtering using Cosine Similarity\",\n",
    "    \"option3\" : \"Neural Collaborative Filtering using Deep Belief Networks (DBN)\",\n",
    "    \"option4\" : \"Collaborative Filtering using User-Item Matrix\",\n",
    "    \"Answer\" : \"option2\",\n",
    "    \"Explanation\" : \"Content Based Filtering using Cosine Similarity is computationally less complex than other recommendation algorithms, making it a suitable choice for smaller datasets.\"\n",
    "  },\n",
    "  {\n",
    "    \"question\" : \"A movie recommendation system is using a user-item matrix with a sparsity level of 99%. Which recommendation algorithm would you suggest for this scenario?\",\n",
    "    \"option1\" : \"Matrix Factorization using Singular Value Decomposition (SVD)\",\n",
    "    \"option2\" : \"Neural Collaborative Filtering using Long Short-Term Memory (LSTM)\",\n",
    "    \"option3\" : \"Content Based Filtering using Term Frequency-Inverse Document Frequency (TF-IDF)\",\n",
    "    \"option4\" : \"Collaborative Filtering using Item-Item Similarity\",\n",
    "    \"Answer\" : \"option1\",\n",
    "    \"Explanation\" : \"Matrix Factorization algorithms like SVD are effective for handling sparse datasets, making it a suitable choice for this scenario.\"\n",
    "  },\n",
    "  {\n",
    "    \"question\" : \"Consider a recommendation system with 100,000 users and 10,000 items. Which algorithm would you recommend for this large-scale scenario, considering the computational complexity and scalability?\",\n",
    "    \"option1\" : \"Collaborative Filtering using User-User Similarity\",\n",
    "    \"option2\" : \"Matrix Factorization using Singular Value Decomposition (SVD)\",\n",
    "    \"option3\" : \"Neural Collaborative Filtering using Deep Belief Networks (DBN)\",\n",
    "    \"option4\" : \"Content Based Filtering using Term Frequency-Inverse Document Frequency (TF-IDF)\",\n",
    "    \"Answer\" : \"option2\",\n",
    "    \"Explanation\" : \"Matrix Factorization algorithms like SVD can handle large-scale datasets efficiently, making it a suitable choice for this scenario.\"\n",
    "  },\n",
    "  {\n",
    "    \"question\" : \"A recommendation system is using a combination of both Content Based Filtering and Collaborative Filtering. The system is observing that users are not satisfied with the recommendations. Which of the following could be the issue?\",\n",
    "    \"option1\" : \"The content features used for Content Based Filtering are not relevant to the users\",\n",
    "    \"option2\" : \"The similarity threshold used for Collaborative Filtering is too high\",\n",
    "    \"option3\" : \"The rating scale used for Collaborative Filtering is not fine-grained enough\",\n",
    "    \"option4\" : \"The user preferences are changing rapidly over time\",\n",
    "    \"Answer\" : \"option4\",\n",
    "    \"Explanation\" : \"User preferences can change rapidly over time, making it difficult for a recommendation system to provide accurate recommendations based on both content and past user behavior. In this case, the system may need to adapt to these changing preferences by updating its models more frequently.\"\n",
    "  }\n",
    "]\n",
    "\"\"\"\n",
    "import json\n",
    "x = json.loads(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "b4fbefcd-550b-4283-bd9a-36c19741147d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'question': 'Consider a user who has rated 15 movies, out of which 10 have a rating of 5 stars and the rest have a rating of 3 stars. A new movie is to be recommended to the user, which of the following methods would be most effective for this scenario?',\n",
       "  'option1': 'Content Based Filtering using cosine similarity',\n",
       "  'option2': 'Matrix Factorization using Singular Value Decomposition (SVD)',\n",
       "  'option3': 'Collaborative Filtering using User-User Similarity',\n",
       "  'option4': 'Collaborative Filtering using Item-Item Similarity',\n",
       "  'Answer': 'option3',\n",
       "  'Explanation': \"In this scenario, the user's preferences are skewed towards a specific rating, hence User-User Similarity based Collaborative Filtering would be the most effective approach to recommend a movie that the user is likely to rate highly.\"},\n",
       " {'question': 'Given a dataset with 100 users, 50 items, and 500 ratings, which recommendation algorithm would you recommend for this scenario, considering the computational complexity?',\n",
       "  'option1': 'Matrix Factorization using Alternating Least Squares (ALS)',\n",
       "  'option2': 'Content Based Filtering using Cosine Similarity',\n",
       "  'option3': 'Neural Collaborative Filtering using Deep Belief Networks (DBN)',\n",
       "  'option4': 'Collaborative Filtering using User-Item Matrix',\n",
       "  'Answer': 'option2',\n",
       "  'Explanation': 'Content Based Filtering using Cosine Similarity is computationally less complex than other recommendation algorithms, making it a suitable choice for smaller datasets.'},\n",
       " {'question': 'A movie recommendation system is using a user-item matrix with a sparsity level of 99%. Which recommendation algorithm would you suggest for this scenario?',\n",
       "  'option1': 'Matrix Factorization using Singular Value Decomposition (SVD)',\n",
       "  'option2': 'Neural Collaborative Filtering using Long Short-Term Memory (LSTM)',\n",
       "  'option3': 'Content Based Filtering using Term Frequency-Inverse Document Frequency (TF-IDF)',\n",
       "  'option4': 'Collaborative Filtering using Item-Item Similarity',\n",
       "  'Answer': 'option1',\n",
       "  'Explanation': 'Matrix Factorization algorithms like SVD are effective for handling sparse datasets, making it a suitable choice for this scenario.'},\n",
       " {'question': 'Consider a recommendation system with 100,000 users and 10,000 items. Which algorithm would you recommend for this large-scale scenario, considering the computational complexity and scalability?',\n",
       "  'option1': 'Collaborative Filtering using User-User Similarity',\n",
       "  'option2': 'Matrix Factorization using Singular Value Decomposition (SVD)',\n",
       "  'option3': 'Neural Collaborative Filtering using Deep Belief Networks (DBN)',\n",
       "  'option4': 'Content Based Filtering using Term Frequency-Inverse Document Frequency (TF-IDF)',\n",
       "  'Answer': 'option2',\n",
       "  'Explanation': 'Matrix Factorization algorithms like SVD can handle large-scale datasets efficiently, making it a suitable choice for this scenario.'},\n",
       " {'question': 'A recommendation system is using a combination of both Content Based Filtering and Collaborative Filtering. The system is observing that users are not satisfied with the recommendations. Which of the following could be the issue?',\n",
       "  'option1': 'The content features used for Content Based Filtering are not relevant to the users',\n",
       "  'option2': 'The similarity threshold used for Collaborative Filtering is too high',\n",
       "  'option3': 'The rating scale used for Collaborative Filtering is not fine-grained enough',\n",
       "  'option4': 'The user preferences are changing rapidly over time',\n",
       "  'Answer': 'option4',\n",
       "  'Explanation': 'User preferences can change rapidly over time, making it difficult for a recommendation system to provide accurate recommendations based on both content and past user behavior. In this case, the system may need to adapt to these changing preferences by updating its models more frequently.'}]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c0e0857-bc4b-4eba-b9f7-1276c2297ebb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:miniconda3-OpenShape]",
   "language": "python",
   "name": "conda-env-miniconda3-OpenShape-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
