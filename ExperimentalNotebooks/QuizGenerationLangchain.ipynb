{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d9b37512-1588-4f3d-ac78-3905afa99e72",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.llms.huggingface_pipeline import HuggingFacePipeline\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline, GenerationConfig\n",
    "import torch\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import LLMChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ca9c57e7-1bae-4a78-a9da-d554dbb39c9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a9dc111419f400d8eaa4e6176936457",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_id = \"mistralai/Mistral-7B-Instruct-v0.2\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_id, torch_dtype=torch.float16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a9fe7de9-ebab-4966-9c1e-025ffceda33c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = pipeline(\"text-generation\", \n",
    "                model=model, \n",
    "                tokenizer=tokenizer,\n",
    "                device=0, \n",
    "                max_new_tokens=2000,\n",
    "                do_sample=True, \n",
    "                top_k=20, \n",
    "                top_p=0.7,\n",
    "                early_stopping=True,\n",
    "                num_beams=2\n",
    "               )\n",
    "hf = HuggingFacePipeline(pipeline=pipe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1132a0e2-110a-40c7-ae1c-b75064dc57d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nOutput Format\\n\\nQuestion : [Insert Question Here]\\nChoice1 : [Insert Choice1 Here]\\nChoice2 : [Insert Choice2 Here]\\nChoice3 : [Insert Choice3 Here]\\nChoice4 : [Insert Choice4 Here]\\nAnswer  : [Correct choice out of the 4 given choices]\\nExplanation : [Explanation of the correct choice]\\n'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# template = \"\"\"\n",
    "# Create five {difficulty} quiz questions suitable for graduate students, focusing on advanced topics in {subject}. \n",
    "# Each question should present a significant challenge, aligning with master's level coursework, and should ideally incorporate real-world applications or data to contextualize the mathematical or statistical concepts involved. \n",
    "# Ensure the questions demand a deep understanding and application of theoretical principles, possibly involving multiple steps or the integration of several concepts.\n",
    "\n",
    "# For each question, provide four choices, making sure the correct answer is included among them. \n",
    "# Additionally, include a detailed explanation for each answer, elaborating on the mathematical or statistical reasoning, the steps involved in arriving at the solution, and any relevant theoretical concepts that underpin the solution. \n",
    "# The explanations should serve not only to justify the correct answer but also to enhance understanding of the subject matter.\n",
    "\n",
    "# Output Format:\n",
    "\n",
    "# Question: [Insert question here, ensuring it requires application of advanced concepts]\n",
    "# Choice1: [Insert choice here]\n",
    "# Choice2: [Insert choice here]\n",
    "# Choice3: [Insert choice here]\n",
    "# Choice4: [Insert choice here]\n",
    "# Answer: [Specify the correct choice Only]\n",
    "# Explanation: [Provide a detailed explanation that covers the reasoning, the solution process, and relevant theoretical background]\n",
    "# \"\"\"\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Output Format\n",
    "\n",
    "Question : [Insert Question Here]\n",
    "Choice1 : [Insert Choice1 Here]\n",
    "Choice2 : [Insert Choice2 Here]\n",
    "Choice3 : [Insert Choice3 Here]\n",
    "Choice4 : [Insert Choice4 Here]\n",
    "Answer  : [Correct choice out of the 4 given choices]\n",
    "Explanation : [Explanation of the correct choice]\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "741ed982-42f1-4a62-aa09-dc8586f1cecc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aagarwal/miniconda3/envs/OpenShape/lib/python3.9/site-packages/transformers/pipelines/base.py:1157: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Question 1:\n",
      "Question: Given a dataset of customer transactions, how would you determine the optimal number of clusters using the Elbow Method? Explain the intuition behind this method and how it can be applied to different distance metrics.\n",
      "\n",
      "Choice1: By calculating the sum of squared errors (SSE) for a range of k values and plotting it against k, the optimal number of clusters is the point where the rate of decrease in SSE starts to level off.\n",
      "Choice2: By calculating the silhouette score for a range of k values and selecting the value of k with the highest average silhouette score.\n",
      "Choice3: By calculating the Dunn Index for a range of k values and selecting the value of k with the highest index value.\n",
      "Choice4: By calculating the Davies-Bouldin Index for a range of k values and selecting the value of k with the lowest index value.\n",
      "Answer: Choice1\n",
      "Explanation: The Elbow Method is based on the idea that as the number of clusters (k) increases, the rate of decrease in the sum of squared errors (SSE) will eventually level off. This point, known as the elbow, represents the optimal number of clusters for the given dataset. The method can be applied to different distance metrics, such as Euclidean, Manhattan, or Cosine distance, by calculating the corresponding SSE for each k value.\n",
      "\n",
      "Question 2:\n",
      "Question: Consider a dataset of gene expression levels for a set of cancer patients. You are tasked with clustering the patients based on their gene expression profiles to identify potential subtypes of the disease. Which clustering algorithm would you recommend and why?\n",
      "\n",
      "Choice1: DBSCAN, due to its ability to discover clusters of arbitrary shapes and densities, making it suitable for identifying complex subtypes of cancer.\n",
      "Choice2: K-Means, due to its simplicity and efficiency, making it a good choice for large datasets with well-defined clusters.\n",
      "Choice3: Hierarchical Clustering, due to its ability to provide a hierarchical structure of clusters, which can be useful for understanding the relationships between different subtypes of cancer.\n",
      "Choice4: Spectral Clustering, due to its ability to handle high-dimensional data and noise, making it a good choice for gene expression data with a large number of features.\n",
      "Answer: Choice3\n",
      "Explanation: Hierarchical Clustering is a suitable choice for clustering gene expression data in cancer patients because it can provide a hierarchical structure of clusters, which can help in understanding the relationships between different subtypes of cancer. This hierarchical structure can be visualized using a dendrogram, which can provide insights into the clustering results and help in identifying potential subtypes of the disease.\n",
      "\n",
      "Question 3:\n",
      "Question: Given a dataset of customer reviews for a restaurant, how would you preprocess the text data to prepare it for clustering using TF-IDF and Cosine Similarity?\n",
      "\n",
      "Choice1: Convert the text data into a bag-of-words representation, remove stop words, and apply stemming or lemmatization before calculating the TF-IDF weights and performing Cosine Similarity.\n",
      "Choice2: Perform text normalization, such as lowercasing and removing punctuation, before calculating the TF-IDF weights and performing Cosine Similarity.\n",
      "Choice3: Apply word embedding techniques, such as Word2Vec or Doc2Vec, before calculating the TF-IDF weights and performing Cosine Similarity.\n",
      "Choice4: Perform text summarization, such as extracting key phrases or using Latent Dirichlet Allocation (LDA), before calculating the TF-IDF weights and performing Cosine Similarity.\n",
      "Answer: Choice1\n",
      "Explanation: To prepare text data for clustering using TF-IDF and Cosine Similarity, the text data should first be converted into a bag-of-words representation. Stop words should then be removed, and stemming or lemmatization should be applied to reduce words to their root form. These preprocessing steps help in reducing the dimensionality of the data and improving the accuracy of the clustering results.\n",
      "\n",
      "Question 4:\n",
      "Question: Given a dataset of customer transactions for an e-commerce website, how would you evaluate the performance of a clustering algorithm in terms of its ability to identify meaningful customer segments?\n",
      "\n",
      "Choice1: By calculating the silhouette score, which measures the similarity of each data point to its own cluster compared to other clusters, and selecting the value of k with the highest average silhouette score.\n",
      "Choice2: By calculating the Davies-Bouldin Index, which measures the similarity between each cluster and its most similar neighboring cluster, and selecting the value of k with the lowest index value.\n",
      "Choice3: By calculating the adjusted Rand index, which measures the similarity between the true labels and the predicted labels, and selecting the value of k with the highest index value.\n",
      "Choice4: By calculating the normalized mutual information, which measures the amount of information shared between the true labels and the predicted labels, and selecting the value of k with the highest mutual information.\n",
      "Answer: Choice3\n",
      "Explanation: To evaluate the performance of a clustering algorithm in terms of its ability to identify meaningful customer segments, the adjusted Rand index can be used. The adjusted Rand index measures the similarity between the true labels and the predicted labels, taking into account the chance level of agreement. A higher adjusted Rand index indicates better clustering performance, as the algorithm is able to identify customer segments that are similar to the true customer segments.\n"
     ]
    }
   ],
   "source": [
    "# Define the prompt template with placeholders for difficulty and subject\n",
    "# The questions should be mathematical and statistical as well.\n",
    "template = \"\"\"\n",
    "Generate {num_questions} {difficulty} quiz questions for graduate students focused on the topic of {subject}. \n",
    "Each question should present a significant challenge, aligning with master's level coursework, and should ideally incorporate real-world applications or data to contextualize the mathematical or statistical concepts involved. \n",
    "Ensure the questions demand a deep understanding and application of theoretical principles, possibly involving multiple steps or the integration of several concepts.\n",
    "\n",
    "The answer should definitely be one of the Choices.\n",
    "\n",
    "Here is the desired JSON structure for each question:\n",
    "\n",
    "Output Format:\n",
    "\n",
    "Question : [Insert Question Here]\n",
    "Choice1 : [Insert Choice1 Here]\n",
    "Choice2 : [Insert Choice2 Here]\n",
    "Choice3 : [Insert Choice3 Here]\n",
    "Choice4 : [Insert Choice4 Here]\n",
    "Answer  : [Correct choice out of the 4 given choices]\n",
    "Explanation : [Explanation of the correct choice]\n",
    "\"\"\"\n",
    "\n",
    "# Create a PromptTemplate instance from the template\n",
    "prompt_template = PromptTemplate.from_template(template)\n",
    "\n",
    "# Example usage of the prompt template to generate a question\n",
    "difficulty = \"medium\"  # You can vary this between \"easy\", \"medium\", \"hard\", etc.\n",
    "subject = \"Clustering\"\n",
    "num_questions = 4\n",
    "\n",
    "chain = prompt_template | hf\n",
    "# Use the prompt template with Langchain to generate the quiz\n",
    "# Assuming you have a Langchain pipeline or chain set up as `langchain_pipeline`\n",
    "generated_quiz = chain.invoke({\n",
    "    \"num_questions\" : num_questions,\n",
    "    \"difficulty\": difficulty,\n",
    "    \"subject\": subject\n",
    "})\n",
    "\n",
    "# Print the generated quiz in JSON format\n",
    "print(generated_quiz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ffd41981-df52-4302-913e-5a22af3a60be",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aagarwal/miniconda3/envs/OpenShape/lib/python3.9/site-packages/transformers/pipelines/base.py:1157: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Question 1:\n",
      "Question: Given a dataset of customer transactions, which clustering algorithm would you recommend to identify groups of customers with similar purchasing behavior, and why?\n",
      "Choice1: DBSCAN\n",
      "Choice2: K-Means\n",
      "Choice3: Hierarchical Clustering\n",
      "Choice4: Spectral Clustering\n",
      "Answer: Choice2: K-Means\n",
      "Explanation: K-Means is a centroid-based clustering algorithm, which works well when the clusters are spherical and well-separated. In this case, we are looking for groups of customers with similar purchasing behavior, which can often be modeled as spherical clusters.\n",
      "\n",
      "Question 2:\n",
      "Question: Consider the following dataset of 1000 points in a 2-dimensional space. Each point is represented by a pair of features (x, y). Given that the true number of clusters is unknown, which clustering algorithm would you recommend, and why?\n",
      "Choice1: DBSCAN\n",
      "Choice2: K-Means\n",
      "Choice3: Hierarchical Clustering\n",
      "Choice4: Spectral Clustering\n",
      "Answer: Choice1: DBSCAN\n",
      "Explanation: DBSCAN (Density-Based Spatial Clustering of Applications with Noise) is a density-based clustering algorithm that can handle clusters of arbitrary shapes and sizes. It does not require the specification of the number of clusters beforehand, making it a good choice when the true number of clusters is unknown.\n",
      "\n",
      "Question 3:\n",
      "Question: Given a dataset of gene expression levels for a set of cancer patients, which clustering algorithm would you recommend to identify distinct subtypes of cancer, and why?\n",
      "Choice1: DBSCAN\n",
      "Choice2: K-Means\n",
      "Choice3: Hierarchical Clustering\n",
      "Choice4: Spectral Clustering\n",
      "Answer: Choice3: Hierarchical Clustering\n",
      "Explanation: Hierarchical Clustering is a tree-based clustering algorithm that can reveal the hierarchical structure of the data. In the context of cancer subtyping, it can help identify groups of patients with similar gene expression profiles that may represent distinct subtypes. Additionally, it can provide a dendrogram, which can be used to visualize the relationships between different subtypes.\n",
      "\n",
      "Question 4:\n",
      "Question: Given a dataset of tweets related to a particular topic, which clustering algorithm would you recommend to identify distinct themes or topics within the data, and why?\n",
      "Choice1: DBSCAN\n",
      "Choice2: K-Means\n",
      "Choice3: Hierarchical Clustering\n",
      "Choice4: Latent Dirichlet Allocation (LDA)\n",
      "Answer: Choice4: Latent Dirichlet Allocation (LDA)\n",
      "Explanation: Latent Dirichlet Allocation (LDA) is a probabilistic model for topic modeling, which can be considered a type of clustering algorithm. It is particularly well-suited for text data, such as tweets, and can help identify distinct themes or topics within the data by modeling the distribution of words across documents (tweets) and topics.\n"
     ]
    }
   ],
   "source": [
    "generated_quiz = chain.invoke({\n",
    "    \"num_questions\" : num_questions,\n",
    "    \"difficulty\": difficulty,\n",
    "    \"subject\": subject\n",
    "})\n",
    "\n",
    "# Print the generated quiz in JSON format\n",
    "print(generated_quiz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d9acea51-7e0f-445b-a2d7-f1a2c4a3baef",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aagarwal/miniconda3/envs/OpenShape/lib/python3.9/site-packages/transformers/pipelines/base.py:1157: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Question 1:\n",
      "Question: Given a dataset of customer transactions, identify the optimal number of clusters using the elbow method. The dataset includes features such as age, gender, income, and transaction amount. Which of the following plots would best represent the elbow point?\n",
      "Choice1: A plot of the sum of squared errors (SSE) against the number of clusters.\n",
      "Choice2: A plot of the log-likelihood against the number of clusters.\n",
      "Choice3: A plot of the silhouette score against the number of clusters.\n",
      "Choice4: A plot of the within-cluster variance against the number of clusters.\n",
      "Answer: Choice1\n",
      "Explanation: The elbow method identifies the optimal number of clusters based on the point where the decrease in SSE starts leveling off.\n",
      "\n",
      "Question 2:\n",
      "Question: Consider a dataset of 1000 points in a 2-dimensional space. You want to apply DBSCAN clustering with a radius of 1.5 and a minimum number of points in a cluster of 5. Which of the following statements is true?\n",
      "Choice1: All points within a distance of 1.5 units from a given point will be assigned to the same cluster.\n",
      "Choice2: All points within a distance of 1.5 units from a given point and having at least 5 neighboring points will be assigned to the same cluster.\n",
      "Choice3: All points within a distance of 1.5 units from a given point and having at least 5 neighboring points with the same label will be assigned to the same cluster.\n",
      "Choice4: All points within a distance of 1.5 units from a given point and having at least 5 neighboring points with different labels will be assigned to the same cluster.\n",
      "Answer: Choice2\n",
      "Explanation: DBSCAN assigns points to the same cluster if they are within a given radius (1.5 units in this case) and have a minimum number of neighboring points (5 in this case).\n",
      "\n",
      "Question 3:\n",
      "Question: Given a dataset of 10,000 points in a 3-dimensional space, which clustering algorithm would be most suitable for identifying clusters with varying densities?\n",
      "Choice1: K-means clustering\n",
      "Choice2: DBSCAN clustering\n",
      "Choice3: Hierarchical clustering\n",
      "Choice4: Spectral clustering\n",
      "Answer: Choice2\n",
      "Explanation: DBSCAN is particularly well-suited for identifying clusters with varying densities, as it does not require the specification of the number of clusters in advance and can effectively handle noise and outliers.\n",
      "\n",
      "Question 4:\n",
      "Question: Given a dataset of 5000 customer reviews, you want to apply text clustering to group similar reviews together. Which of the following techniques would be most suitable for this task?\n",
      "Choice1: K-means clustering\n",
      "Choice2: DBSCAN clustering\n",
      "Choice3: Hierarchical clustering\n",
      "Choice4: Latent Dirichhet Allocation (LDA)\n",
      "Answer: Choice4\n",
      "Explanation: LDA is a popular technique for text clustering, as it can effectively identify latent topics in a large corpus of text data and group similar reviews together based on their underlying topics.\n"
     ]
    }
   ],
   "source": [
    "generated_quiz = chain.invoke({\n",
    "    \"num_questions\" : num_questions,\n",
    "    \"difficulty\": difficulty,\n",
    "    \"subject\": subject\n",
    "})\n",
    "\n",
    "# Print the generated quiz in JSON format\n",
    "print(generated_quiz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3692f820-630a-4660-b6a4-d981a20912d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Question 1:\n",
      "Question: Given a dataset of customer transactions, identify the optimal number of clusters using the elbow method. The dataset includes features such as age, gender, income, and transaction amount. Which of the following plots would best represent the elbow point?\n",
      "Choice1: A plot of the sum of squared errors (SSE) against the number of clusters.\n",
      "Choice2: A plot of the log-likelihood against the number of clusters.\n",
      "Choice3: A plot of the silhouette score against the number of clusters.\n",
      "Choice4: A plot of the within-cluster variance against the number of clusters.\n",
      "Answer: Choice1\n",
      "Explanation: The elbow method identifies the optimal number of clusters based on the point where the decrease in SSE starts leveling off.\n",
      "\n",
      "Question 2:\n",
      "Question: Consider a dataset of 1000 points in a 2-dimensional space. You want to apply DBSCAN clustering with a radius of 1.5 and a minimum number of points in a cluster of 5. Which of the following statements is true?\n",
      "Choice1: All points within a distance of 1.5 units from a given point will be assigned to the same cluster.\n",
      "Choice2: All points within a distance of 1.5 units from a given point and having at least 5 neighboring points will be assigned to the same cluster.\n",
      "Choice3: All points within a distance of 1.5 units from a given point and having at least 5 neighboring points with the same label will be assigned to the same cluster.\n",
      "Choice4: All points within a distance of 1.5 units from a given point and having at least 5 neighboring points with different labels will be assigned to the same cluster.\n",
      "Answer: Choice2\n",
      "Explanation: DBSCAN assigns points to the same cluster if they are within a given radius (1.5 units in this case) and have a minimum number of neighboring points (5 in this case).\n",
      "\n",
      "Question 3:\n",
      "Question: Given a dataset of 10,000 points in a 3-dimensional space, which clustering algorithm would be most suitable for identifying clusters with varying densities?\n",
      "Choice1: K-means clustering\n",
      "Choice2: DBSCAN clustering\n",
      "Choice3: Hierarchical clustering\n",
      "Choice4: Spectral clustering\n",
      "Answer: Choice2\n",
      "Explanation: DBSCAN is particularly well-suited for identifying clusters with varying densities, as it does not require the specification of the number of clusters in advance and can effectively handle noise and outliers.\n",
      "\n",
      "Question 4:\n",
      "Question: Given a dataset of 5000 customer reviews, you want to apply text clustering to group similar reviews together. Which of the following techniques would be most suitable for this task?\n",
      "Choice1: K-means clustering\n",
      "Choice2: DBSCAN clustering\n",
      "Choice3: Hierarchical clustering\n",
      "Choice4: Latent Dirichhet Allocation (LDA)\n",
      "Answer: Choice4\n",
      "Explanation: LDA is a popular technique for text clustering, as it can effectively identify latent topics in a large corpus of text data and group similar reviews together based on their underlying topics.\n"
     ]
    }
   ],
   "source": [
    "for _ in generated_quiz.split('\\n'):\n",
    "    print(_.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f5657296-42e5-4e06-b450-93b1d44f727b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import re\n",
    "\n",
    "class QuizQuestionJSONFormatter:\n",
    "    def __init__(self, text_input):\n",
    "        self.text_input = text_input\n",
    "\n",
    "    def parse_questions(self):\n",
    "        # Split the text input into chunks based on the question pattern\n",
    "        question_blocks = re.split(r'Question \\d+:', self.text_input)[1:]\n",
    "        return question_blocks\n",
    "\n",
    "    def extract_choices(self, block):\n",
    "        # Extract choices from the block\n",
    "        choices_pattern = r'Choice\\d+: ([^\\n]+)'\n",
    "        choices = re.findall(choices_pattern, block)\n",
    "        return choices\n",
    "\n",
    "    def format_json(self):\n",
    "        # Parse each question block and format it into JSON\n",
    "        question_blocks = self.parse_questions()\n",
    "        formatted_questions = []\n",
    "\n",
    "        for block in question_blocks:\n",
    "            # Extract question, answer, and explanation using regular expressions\n",
    "            question = re.search(r'([^\\n]+)', block).group(1).strip()\n",
    "            choices = self.extract_choices(block)\n",
    "            answer = re.search(r'Answer: (Choice\\d+)', block).group(1).strip()\n",
    "            explanation = re.search(r'Explanation: ([^\\n]+)', block).group(1).strip()\n",
    "\n",
    "            # Build the JSON object\n",
    "            question_json = {\n",
    "                \"Question\": question,\n",
    "                \"Choices\": choices,\n",
    "                \"Answer\": answer,\n",
    "                \"Explanation\": explanation\n",
    "            }\n",
    "            formatted_questions.append(question_json)\n",
    "\n",
    "        return json.dumps(formatted_questions, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ef2c9f53-fa0c-4fc7-bd7b-1b7c55416edb",
   "metadata": {},
   "outputs": [],
   "source": [
    "ac = QuizQuestionJSONFormatter(text_input=generated_quiz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7d6dbce4-06ca-4fcb-8a35-f394394a83c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = json.loads(ac.format_json())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ac1b9aca-e07d-4984-a67f-b158cc441934",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Question': 'Question: Consider a dataset of 1000 points in a 2-dimensional space. You want to apply DBSCAN clustering with a radius of 1.5 and a minimum number of points in a cluster of 5. Which of the following statements is true?',\n",
       " 'Choices': ['All points within a distance of 1.5 units from a given point will be assigned to the same cluster.',\n",
       "  'All points within a distance of 1.5 units from a given point and having at least 5 neighboring points will be assigned to the same cluster.',\n",
       "  'All points within a distance of 1.5 units from a given point and having at least 5 neighboring points with the same label will be assigned to the same cluster.',\n",
       "  'All points within a distance of 1.5 units from a given point and having at least 5 neighboring points with different labels will be assigned to the same cluster.'],\n",
       " 'Answer': 'Choice2',\n",
       " 'Explanation': 'DBSCAN assigns points to the same cluster if they are within a given radius (1.5 units in this case) and have a minimum number of neighboring points (5 in this case).'}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8e4cc51-bc72-416a-b0a8-c6b1b0868d7f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:miniconda3-OpenShape]",
   "language": "python",
   "name": "conda-env-miniconda3-OpenShape-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
